{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwb8n-j9EGdF"
      },
      "outputs": [],
      "source": [
        "#Import generic datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#Import all required Keras modeling datasets\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers import ReLU "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFMsg-ONEGdH"
      },
      "outputs": [],
      "source": [
        "dir = os.getcwd()\n",
        "print(\"Current Dir: \", dir)\n",
        "train_dir = os.path.join(dir, \"train\")\n",
        "print(\"Train Dir: \", train_dir)\n",
        "train_files = os.listdir(train_dir)\n",
        "train_labels = []\n",
        "for file in train_files:\n",
        "    identifier = file.split('.')[0]\n",
        "    if identifier ==  'dog':\n",
        "        train_labels.append(1)\n",
        "    elif identifier == 'cat':\n",
        "        train_labels.append(0)\n",
        "    else:\n",
        "        train_labels.append('Error')\n",
        "train_df_orig = pd.DataFrame({'img': train_files, 'label': train_labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enDVx5ciEGdI",
        "outputId": "aa8e8980-eefb-44db-e679-4fc73557a0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                img  label\n",
            "0         cat.0.jpg      0\n",
            "1         cat.1.jpg      0\n",
            "2        cat.10.jpg      0\n",
            "3       cat.100.jpg      0\n",
            "4      cat.1000.jpg      0\n",
            "...             ...    ...\n",
            "24995  dog.9995.jpg      1\n",
            "24996  dog.9996.jpg      1\n",
            "24997  dog.9997.jpg      1\n",
            "24998  dog.9998.jpg      1\n",
            "24999  dog.9999.jpg      1\n",
            "\n",
            "[25000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(train_df_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWdiu6HuEGdJ"
      },
      "outputs": [],
      "source": [
        "#All images need to be the same size\n",
        "import cv2\n",
        "def resize_images(input_dir, output_dir, target_size=(500, 500)):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            img = cv2.imread(os.path.join(input_dir, filename))\n",
        "            if img.shape[:2] != target_size:\n",
        "                resized_img = cv2.resize(img, target_size)\n",
        "                cv2.imwrite(os.path.join(output_dir, filename), resized_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc8zZBZvEGdJ"
      },
      "outputs": [],
      "source": [
        "train_dir_resize = os.path.join(dir, \"train_dir_resize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_ai-PI4EGdK"
      },
      "outputs": [],
      "source": [
        "#Only needs to be run on our first take with the dataset\n",
        "resize_images(train_dir, train_dir_resize)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kw6jkkVEGdK",
        "outputId": "cab53460-37ba-4503-9bab-c3212fca0e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Dir:  c:\\Users\\Connor\\Documents\\AAI628\\Final\\test1\n"
          ]
        }
      ],
      "source": [
        "#Only needs to be run on our first take with the dataset\n",
        "test_dir = os.path.join(dir, \"test1\")\n",
        "print(\"Test Dir: \", test_dir)\n",
        "test_dir_resize = os.path.join(dir, \"test_dir_resize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQgaRiQcEGdL"
      },
      "outputs": [],
      "source": [
        "#Only needs to be run on our first take with the dataset\n",
        "resize_images(test_dir, test_dir_resize)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0PnVd96EGdL"
      },
      "outputs": [],
      "source": [
        "train_files_resized = os.listdir(train_dir_resize)\n",
        "train_labels_resized = []\n",
        "for file in train_files_resized:\n",
        "    identifier = file.split('.')[0]\n",
        "    if identifier ==  'dog':\n",
        "        train_labels_resized.append(1)\n",
        "    elif identifier == 'cat':\n",
        "        train_labels_resized.append(0)\n",
        "    else:\n",
        "        train_labels_resized.append('Error')\n",
        "train_df_resized = pd.DataFrame({'img': train_files_resized, 'label': train_labels_resized})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfIkT5CDEGdL",
        "outputId": "076c48f9-db83-4012-e1f2-f2a7e7ba71a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                img  label\n",
            "0         cat.0.jpg      0\n",
            "1         cat.1.jpg      0\n",
            "2        cat.10.jpg      0\n",
            "3       cat.100.jpg      0\n",
            "4      cat.1000.jpg      0\n",
            "...             ...    ...\n",
            "24995  dog.9995.jpg      1\n",
            "24996  dog.9996.jpg      1\n",
            "24997  dog.9997.jpg      1\n",
            "24998  dog.9998.jpg      1\n",
            "24999  dog.9999.jpg      1\n",
            "\n",
            "[25000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(train_df_resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJNAD_HEGdM"
      },
      "outputs": [],
      "source": [
        "#Model parameters\n",
        "img_height = 500\n",
        "img_width = 500\n",
        "img_size = (500, 500)\n",
        "channels = 3\n",
        "number_of_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmBGKDCMEGdM"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(500, 500, channels)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(64,(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KlgEk_UEGdN",
        "outputId": "ebeaa804-db96-40c7-af1e-f9db3b86d24e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 498, 498, 32)      896       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 498, 498, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 498, 498, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 496, 496, 32)      9248      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 496, 496, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 248, 248, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 248, 248, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 246, 246, 64)      18496     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 246, 246, 64)      0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 246, 246, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 244, 244, 64)      36928     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 244, 244, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 122, 122, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 952576)            0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 952576)           3810304   \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               487719424 \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 491,596,321\n",
            "Trainable params: 489,690,913\n",
            "Non-trainable params: 1,905,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIHY4kteEGdN"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "#We need to use binary cross entropy, as output will be either a 1 or 0\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyu7gdHAEGdN"
      },
      "outputs": [],
      "source": [
        "image_fit_dir = train_dir_resize\n",
        "batch_size = 32\n",
        "image_generator = ImageDataGenerator(rescale=1.0/255.0)  # Rescale pixel values between 0 and 1\n",
        "target_size = (img_width, img_height)\n",
        "fit_df = train_df_resized\n",
        "fit_df['label'] = fit_df['label'].astype('string')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RFHq045EGdO",
        "outputId": "38fa1b09-7252-4622-916f-25968079ee12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = image_generator.flow_from_dataframe(\n",
        "    fit_df,\n",
        "    directory=image_fit_dir,\n",
        "    x_col='img',\n",
        "    y_col='label',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO7DyRBCEGdO"
      },
      "outputs": [],
      "source": [
        "#Fit the model to my training data\n",
        "epochs = 10\n",
        "model.fit(train_data, epochs = epochs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}